{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "SEC EDGAR Company Filings Scraper - Jimmy Tools"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä SEC EDGAR Company Filings Scraper\n",
        "### Built by Jimmy Tools | jimmytools.net\n",
        "\n",
        "This notebook extracts SEC filings (10-K, 10-Q, 8-K, and more) for any public company.\n",
        "\n",
        "**What you'll get:**\n",
        "- List of all filings with dates and links\n",
        "- Full text extraction from selected filings\n",
        "- Downloadable CSV/Excel export\n",
        "- Keyword search across filings\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "1. Click **Runtime ‚Üí Run all** (or press Ctrl+F9)\n",
        "2. Enter the stock ticker when prompted (e.g., AAPL, TSLA, MSFT)\n",
        "3. Download your results!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîß Setup (runs automatically)\n",
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# SEC requires a user-agent with contact info\n",
        "HEADERS = {\n",
        "    'User-Agent': 'JimmyTools Research Bot (contact@jimmytools.net)',\n",
        "    'Accept-Encoding': 'gzip, deflate',\n",
        "}\n",
        "\n",
        "print(\"‚úÖ Setup complete! Ready to scrape SEC filings.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìù Enter Company Ticker\n",
        "ticker = input(\"Enter stock ticker (e.g., AAPL, TSLA, MSFT): \").strip().upper()\n",
        "print(f\"\\nüîç Looking up {ticker}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üè¢ Get Company CIK (SEC Identifier)\n",
        "\n",
        "def get_cik(ticker):\n",
        "    \"\"\"Convert ticker to SEC CIK number\"\"\"\n",
        "    url = 'https://www.sec.gov/files/company_tickers.json'\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    data = response.json()\n",
        "    \n",
        "    for entry in data.values():\n",
        "        if entry['ticker'].upper() == ticker.upper():\n",
        "            cik = str(entry['cik_str']).zfill(10)\n",
        "            return cik, entry['title']\n",
        "    return None, None\n",
        "\n",
        "cik, company_name = get_cik(ticker)\n",
        "\n",
        "if cik:\n",
        "    print(f\"‚úÖ Found: {company_name}\")\n",
        "    print(f\"   CIK: {cik}\")\n",
        "else:\n",
        "    print(f\"‚ùå Ticker '{ticker}' not found. Please check the symbol and try again.\")\n",
        "    raise SystemExit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìã Select Filing Types\n",
        "\n",
        "print(\"Which filings do you want to retrieve?\\n\")\n",
        "print(\"1. 10-K (Annual Reports)\")\n",
        "print(\"2. 10-Q (Quarterly Reports)\")\n",
        "print(\"3. 8-K (Current Reports / Material Events)\")\n",
        "print(\"4. All of the above\")\n",
        "print(\"5. All filings (includes proxy statements, insider trading, etc.)\")\n",
        "\n",
        "choice = input(\"\\nEnter choice (1-5): \").strip()\n",
        "\n",
        "filing_types = {\n",
        "    '1': ['10-K', '10-K/A'],\n",
        "    '2': ['10-Q', '10-Q/A'],\n",
        "    '3': ['8-K', '8-K/A'],\n",
        "    '4': ['10-K', '10-K/A', '10-Q', '10-Q/A', '8-K', '8-K/A'],\n",
        "    '5': None  # None means all types\n",
        "}\n",
        "\n",
        "selected_types = filing_types.get(choice, filing_types['4'])\n",
        "if selected_types:\n",
        "    print(f\"\\n‚úÖ Will retrieve: {', '.join(selected_types)}\")\n",
        "else:\n",
        "    print(f\"\\n‚úÖ Will retrieve ALL filing types\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üì• Fetch All Filings from SEC EDGAR\n",
        "\n",
        "def get_filings(cik, filing_types=None):\n",
        "    \"\"\"Get all filings for a company from SEC EDGAR\"\"\"\n",
        "    url = f'https://data.sec.gov/submissions/CIK{cik}.json'\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    data = response.json()\n",
        "    \n",
        "    filings = []\n",
        "    recent = data.get('filings', {}).get('recent', {})\n",
        "    \n",
        "    if not recent:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    for i in range(len(recent.get('accessionNumber', []))):\n",
        "        form_type = recent['form'][i]\n",
        "        \n",
        "        # Filter by filing type if specified\n",
        "        if filing_types and form_type not in filing_types:\n",
        "            continue\n",
        "            \n",
        "        accession = recent['accessionNumber'][i].replace('-', '')\n",
        "        primary_doc = recent['primaryDocument'][i]\n",
        "        \n",
        "        filing = {\n",
        "            'form_type': form_type,\n",
        "            'filing_date': recent['filingDate'][i],\n",
        "            'accession_number': recent['accessionNumber'][i],\n",
        "            'description': recent.get('primaryDocDescription', [''])[i] if i < len(recent.get('primaryDocDescription', [])) else '',\n",
        "            'document_url': f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession}/{primary_doc}\",\n",
        "            'filing_url': f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession}\",\n",
        "        }\n",
        "        filings.append(filing)\n",
        "    \n",
        "    return pd.DataFrame(filings)\n",
        "\n",
        "print(f\"\\n‚è≥ Fetching filings for {company_name}...\")\n",
        "df_filings = get_filings(cik, selected_types)\n",
        "\n",
        "print(f\"\\n‚úÖ Found {len(df_filings)} filings!\\n\")\n",
        "print(\"Filing types breakdown:\")\n",
        "print(df_filings['form_type'].value_counts().to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üëÄ Preview Filings\n",
        "\n",
        "print(f\"\\nüìã Most Recent Filings for {company_name}\\n\")\n",
        "print(df_filings[['form_type', 'filing_date', 'description']].head(20).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üìÑ Extract Full Text from Recent Filings (Optional)\n",
        "\n",
        "extract_text = input(\"\\nExtract full text from filings? This takes longer but enables keyword search. (y/n): \").strip().lower()\n",
        "\n",
        "if extract_text == 'y':\n",
        "    num_to_extract = input(\"How many recent filings to extract? (default: 10): \").strip()\n",
        "    num_to_extract = int(num_to_extract) if num_to_extract.isdigit() else 10\n",
        "    \n",
        "    def extract_filing_text(url):\n",
        "        \"\"\"Extract text content from a filing\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, headers=HEADERS, timeout=30)\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "            \n",
        "            # Remove scripts and styles\n",
        "            for tag in soup(['script', 'style', 'meta', 'link']):\n",
        "                tag.decompose()\n",
        "            \n",
        "            text = soup.get_text(separator=' ', strip=True)\n",
        "            # Clean up whitespace\n",
        "            text = re.sub(r'\\s+', ' ', text)\n",
        "            return text[:50000]  # Limit to 50k chars per filing\n",
        "        except Exception as e:\n",
        "            return f\"Error extracting: {str(e)}\"\n",
        "    \n",
        "    print(f\"\\n‚è≥ Extracting text from {num_to_extract} filings (this may take a minute)...\\n\")\n",
        "    \n",
        "    texts = []\n",
        "    for i, row in df_filings.head(num_to_extract).iterrows():\n",
        "        print(f\"  Processing {row['form_type']} from {row['filing_date']}...\")\n",
        "        text = extract_filing_text(row['document_url'])\n",
        "        texts.append(text)\n",
        "        time.sleep(0.2)  # Be nice to SEC servers\n",
        "    \n",
        "    df_filings.loc[df_filings.index[:num_to_extract], 'full_text'] = texts\n",
        "    print(f\"\\n‚úÖ Text extraction complete!\")\n",
        "else:\n",
        "    print(\"\\n‚è© Skipping text extraction.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üîç Search Filings for Keywords (Optional)\n",
        "\n",
        "if 'full_text' in df_filings.columns:\n",
        "    search_term = input(\"\\nEnter keyword to search (or press Enter to skip): \").strip()\n",
        "    \n",
        "    if search_term:\n",
        "        print(f\"\\nüîç Searching for '{search_term}'...\\n\")\n",
        "        \n",
        "        results = []\n",
        "        for i, row in df_filings.iterrows():\n",
        "            if pd.notna(row.get('full_text')):\n",
        "                matches = len(re.findall(search_term, row['full_text'], re.IGNORECASE))\n",
        "                if matches > 0:\n",
        "                    results.append({\n",
        "                        'form_type': row['form_type'],\n",
        "                        'filing_date': row['filing_date'],\n",
        "                        'matches': matches,\n",
        "                        'url': row['document_url']\n",
        "                    })\n",
        "        \n",
        "        if results:\n",
        "            df_results = pd.DataFrame(results).sort_values('matches', ascending=False)\n",
        "            print(f\"Found '{search_term}' in {len(results)} filings:\\n\")\n",
        "            print(df_results.to_string(index=False))\n",
        "        else:\n",
        "            print(f\"No matches found for '{search_term}'\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Text extraction was skipped. Run the extraction cell above to enable search.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üíæ Download Results\n",
        "\n",
        "print(\"\\nüì• Preparing downloads...\\n\")\n",
        "\n",
        "# Create filename\n",
        "timestamp = datetime.now().strftime('%Y%m%d')\n",
        "filename_base = f\"{ticker}_SEC_Filings_{timestamp}\"\n",
        "\n",
        "# Save as CSV\n",
        "csv_filename = f\"{filename_base}.csv\"\n",
        "df_filings.to_csv(csv_filename, index=False)\n",
        "print(f\"‚úÖ Saved: {csv_filename}\")\n",
        "\n",
        "# Save as Excel (without full_text column to keep file small)\n",
        "excel_filename = f\"{filename_base}.xlsx\"\n",
        "export_cols = [c for c in df_filings.columns if c != 'full_text']\n",
        "df_filings[export_cols].to_excel(excel_filename, index=False)\n",
        "print(f\"‚úÖ Saved: {excel_filename}\")\n",
        "\n",
        "# Download files\n",
        "print(\"\\nüì• Downloading files to your computer...\")\n",
        "files.download(csv_filename)\n",
        "files.download(excel_filename)\n",
        "\n",
        "print(\"\\nüéâ Done! Check your Downloads folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Summary\n",
        "\n",
        "You've successfully extracted SEC filings for your target company!\n",
        "\n",
        "**What you got:**\n",
        "- Complete list of filings with dates and direct links\n",
        "- Full text extraction (if enabled)\n",
        "- Keyword search results (if searched)\n",
        "- CSV and Excel exports\n",
        "\n",
        "**Next steps:**\n",
        "- Open the CSV/Excel in your spreadsheet app\n",
        "- Click the `document_url` links to read full filings\n",
        "- Re-run this notebook for a different company\n",
        "\n",
        "---\n",
        "\n",
        "### üõ†Ô∏è More Tools at [jimmytools.net](https://jimmytools.net)\n",
        "\n",
        "Questions? [@JimmyToolsAi on X](https://x.com/JimmyToolsAi)\n"
      ]
    }
  ]
}
